{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be94cb9f",
   "metadata": {},
   "source": [
    "step_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰é…ç½®: 4 åˆ†ç±», è¿è¡Œè®¾å¤‡: cuda\n",
      "æ£€æµ‹åˆ°çš„ç±»åˆ«æ˜ å°„: {'class 0': 0, 'class 1': 1, 'class 2': 2, 'class 3': 3}\n",
      "æ•°æ®åŠ è½½å®Œæ¯•ï¼è®­ç»ƒé›†: 5646 å¼ , éªŒè¯é›†: 1412 å¼ \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "# ----------------------\n",
    "# 1. æ ¸å¿ƒé…ç½®\n",
    "# ----------------------\n",
    "CONFIG = {\n",
    "    \"num_classes\": 4,          # 4ç±»\n",
    "    \"img_size\": 256,           # Swin V2 Tiny åˆ†è¾¨ç‡\n",
    "    \"batch_size\": 32,          # æ˜¾å­˜å¤Ÿå¤§å¯ä»¥æ”¹ 64\n",
    "    \"data_dir\": \"D:/IT/CODE/JUPYTER/ConvNeXt_V2/data\", # ä½ çš„è·¯å¾„\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "print(f\"å½“å‰é…ç½®: {CONFIG['num_classes']} åˆ†ç±», è¿è¡Œè®¾å¤‡: {CONFIG['device']}\")\n",
    "\n",
    "# ----------------------\n",
    "# 2. æ•°æ®å¢å¼º (å‡çº§ç‰ˆ)\n",
    "# ----------------------\n",
    "\n",
    "# ã€è®­ç»ƒé›†ã€‘å¼ºæ•°æ®å¢å¼º\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(CONFIG['img_size'], scale=(0.8, 1.0)), \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ã€éªŒè¯é›† & æµ‹è¯•é›†ã€‘æ™®é€šå¤„ç† (åªç¼©æ”¾ï¼Œä¸ä¹±åŠ¨)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# 3. æ•°æ®åŠ è½½\n",
    "# ----------------------\n",
    "# åŠ è½½ä¸¤æ¬¡ï¼šä¸€æ¬¡ä¸ºäº†è®­ç»ƒ(å¼ºå¢å¼º)ï¼Œä¸€æ¬¡ä¸ºäº†éªŒè¯/æµ‹è¯•(æ ‡å‡†å¤„ç†)\n",
    "full_train_ds = datasets.ImageFolder(root=CONFIG['data_dir'], transform=train_transforms)\n",
    "full_val_ds = datasets.ImageFolder(root=CONFIG['data_dir'], transform=val_transforms)\n",
    "\n",
    "# æ‰“å°ç±»åˆ«æ˜ å°„\n",
    "print(\"ç±»åˆ«æ˜ å°„:\", full_train_ds.class_to_idx)\n",
    "\n",
    "# ----------------------\n",
    "# 4. åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›† (8:1:1)\n",
    "# ----------------------\n",
    "# è®¡ç®—æ•°é‡\n",
    "total_len = len(full_train_ds)\n",
    "train_len = int(0.7 * total_len)\n",
    "val_len = int(0.15 * total_len)\n",
    "test_len = total_len - train_len - val_len # å‰©ä¸‹çš„ç»™æµ‹è¯•é›†\n",
    "\n",
    "# è®¾å®šç§å­ç¡®ä¿åˆ‡åˆ†ä¸€è‡´\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "\n",
    "# A. åˆ‡å‡ºè®­ç»ƒé›† (ä½¿ç”¨ full_train_dsï¼Œå¸¦å¼ºå¢å¼º)\n",
    "train_dataset, _, _ = random_split(full_train_ds, [train_len, val_len, test_len], generator=seed)\n",
    "\n",
    "seed = torch.Generator().manual_seed(42) # é‡ç½®ç§å­ï¼Œä½ç½®å¯¹é½\n",
    "\n",
    "# B. åˆ‡å‡ºéªŒè¯é›†å’Œæµ‹è¯•é›† (ä½¿ç”¨ full_val_dsï¼Œå¸¦æ ‡å‡†å¤„ç†)\n",
    "_, val_dataset, test_dataset = random_split(full_val_ds, [train_len, val_len, test_len], generator=seed)\n",
    "\n",
    "# ----------------------\n",
    "# 5. åˆ›å»ºåŠ è½½å™¨\n",
    "# ----------------------\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
    "# æµ‹è¯•é›†ç”¨äºæœ€åå†™æŠ¥å‘Šï¼Œä¸éœ€è¦ shuffle\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"âœ… æ•°æ®åŠ è½½å®Œæ¯•ï¼\")\n",
    "print(f\"è®­ç»ƒé›†: {len(train_dataset)} (å¼ºå¢å¼º)\")\n",
    "print(f\"éªŒè¯é›†: {len(val_dataset)} (æ ‡å‡†)\")\n",
    "print(f\"æµ‹è¯•é›†: {len(test_dataset)} (æ ‡å‡† - ç”¨äºæœ€ç»ˆæŠ¥å‘Š)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd163f6e",
   "metadata": {},
   "source": [
    "step_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# ----------------------\n",
    "# Step 2: å®šä¹‰ LoRA æ¨¡å‹\n",
    "# ----------------------\n",
    "def get_lora_model(num_classes):\n",
    "    print(f\"æ­£åœ¨æ„å»º Swin V2 + LoRA æ¨¡å‹ (Class={num_classes})...\")\n",
    "    \n",
    "    # 1. åŠ è½½åŸºç¡€æ¨¡å‹ (é¢„è®­ç»ƒå¿…é¡»å¼€å¯)\n",
    "    base_model = timm.create_model(\n",
    "        'swinv2_tiny_window16_256', \n",
    "        pretrained=True, \n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    # 2. é…ç½® LoRA\n",
    "    # target_modules: é’ˆå¯¹ Swin çš„æ³¨æ„åŠ›å±‚è¿›è¡Œå¾®è°ƒ\n",
    "    # modules_to_save=[\"head\"]: ã€å…³é”®ã€‘åˆ†ç±»å¤´å¿…é¡»å®Œå…¨è§£å†»ï¼Œå› ä¸ºå®ƒè¦é€‚åº”ä½ çš„4åˆ†ç±»\n",
    "    peft_config = LoraConfig(\n",
    "        r=16,             # ç§©å¤§å°ï¼Œæ§åˆ¶å‚æ•°é‡\n",
    "        lora_alpha=16,    # ç¼©æ”¾ç³»æ•°\n",
    "        target_modules=[\"qkv\", \"proj\", \"fc1\", \"fc2\"], \n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        modules_to_save=[\"head\"] \n",
    "    )\n",
    "    \n",
    "    # 3. åŒ…è£…æ¨¡å‹\n",
    "    model = get_peft_model(base_model, peft_config)\n",
    "    \n",
    "    # æ‰“å°ä¸€ä¸‹æˆ‘ä»¬åªè®­ç»ƒäº†å¤šå°‘å‚æ•°\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    model = model.to(CONFIG['device'])\n",
    "    return model\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = get_lora_model(CONFIG['num_classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216ac0a",
   "metadata": {},
   "source": [
    "step_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a655ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# ----------------------\n",
    "# 1. å‡†å¤‡è®­ç»ƒå·¥å…· (LoRA ç‰ˆ)\n",
    "# ----------------------\n",
    "# ä½¿ç”¨æ ‡ç­¾å¹³æ»‘ï¼Œå¢åŠ æ¨¡å‹æ³›åŒ–èƒ½åŠ›\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# ã€å…³é”®ä¿®æ”¹ã€‘LoRA çš„å‚æ•°å¾ˆå°‘ï¼Œå­¦ä¹ ç‡éœ€è¦å¤§ä¸€ç‚¹ï¼Œé€šå¸¸ç”¨ 1e-3 æˆ– 5e-4\n",
    "# åŸæ¥çš„ 1e-5 å¯¹ LoRA æ¥è¯´å¤ªå°äº†ï¼Œä¼šå¯¼è‡´æ”¶æ•›ä¸åŠ¨\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "\n",
    "# è°ƒåº¦å™¨ (ä½™å¼¦é€€ç«)\n",
    "EPOCHS = 20 \n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
    "\n",
    "# æ··åˆç²¾åº¦\n",
    "scaler = torch.amp.GradScaler('cuda') \n",
    "\n",
    "# ----------------------\n",
    "# 2. å®šä¹‰è®­ç»ƒå‡½æ•° (ä¿æŒåŸæ±åŸå‘³)\n",
    "# ----------------------\n",
    "def train_one_epoch(epoch_index, model, loader, optimizer, criterion, scheduler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch_index} [Train]\", file=sys.stdout)\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(loop):\n",
    "        images, labels = images.to(CONFIG['device']), labels.to(CONFIG['device'])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # æ··åˆç²¾åº¦å‰å‘\n",
    "        with torch.amp.autocast('cuda', dtype=torch.float16):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # ç»Ÿè®¡\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        current_avg_loss = running_loss / (batch_idx + 1)\n",
    "        \n",
    "        # æ˜¾ç¤ºå½“å‰ LR\n",
    "        loop.set_postfix(loss=f\"{current_avg_loss:.4f}\", acc=f\"{100.*correct/total:.2f}%\", lr=f\"{current_lr:.1e}\")\n",
    "        \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# ----------------------\n",
    "# 3. å®šä¹‰éªŒè¯å‡½æ•° (ä¿æŒåŸæ±åŸå‘³)\n",
    "# ----------------------\n",
    "def validate(epoch_index, model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch_index} [Val  ]\", file=sys.stdout)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loop):\n",
    "            images, labels = images.to(CONFIG['device']), labels.to(CONFIG['device'])\n",
    "            \n",
    "            with torch.amp.autocast('cuda', dtype=torch.float16):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            current_avg_loss = val_loss / (batch_idx + 1)\n",
    "            loop.set_postfix(loss=f\"{current_avg_loss:.4f}\", acc=f\"{100.*correct/total:.2f}%\")\n",
    "            \n",
    "    return val_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# ----------------------\n",
    "# 4. å¼€å§‹è®­ç»ƒ\n",
    "# ----------------------\n",
    "best_acc = 0.0\n",
    "print(f\"ğŸ”¥ å¼€å§‹ LoRA å¾®è°ƒè®­ç»ƒ... è®¾å¤‡: {CONFIG['device']}\")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(epoch, model, train_loader, optimizer, criterion, scheduler)\n",
    "    val_loss, val_acc = validate(epoch, model, val_loader, criterion)\n",
    "    \n",
    "    # æ›´æ–°å­¦ä¹ ç‡\n",
    "    scheduler.step()\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model_lora.pth\") # ä¿å­˜ä¸º lora ç‰ˆæ–‡ä»¶å\n",
    "        print(f\"--> ğŸš€ å‘ç°æ–°é«˜! ä¿å­˜æ¨¡å‹ (Val Acc: {val_acc:.2f}%)\")\n",
    "        \n",
    "    print(f\"Epoch {epoch} ç»“æŸ. Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(f\"è®­ç»ƒå®Œæˆï¼æœ€é«˜å‡†ç¡®ç‡: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# æ£€æŸ¥æ˜¯å¦æˆåŠŸè°ƒç”¨äº† CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… æ˜¾å¡å·²å°±ç»ª: {torch.cuda.get_device_name(0)}\")\n",
    "    # æµ‹è¯•ä¸€ä¸‹æ˜¾å­˜å†™å…¥\n",
    "    x = torch.ones(1).cuda()\n",
    "    print(\"âœ… æ˜¾å­˜å†™å…¥æµ‹è¯•é€šè¿‡ï¼\")\n",
    "else:\n",
    "    print(\"âŒ ä¾ç„¶æ²¡æœ‰æ£€æµ‹åˆ°æ˜¾å¡ï¼Œè¯·æˆªå›¾æŠ¥é”™ä¿¡æ¯ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
